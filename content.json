{"meta":{"title":"学习/分享/记录","subtitle":"","description":"个人小站点","author":"张xiao博","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"FaceDetector","slug":"OpenCV/FaceDetector","date":"2022-01-07T01:48:49.000Z","updated":"2022-01-07T01:48:49.970Z","comments":true,"path":"2022/01/07/OpenCV/FaceDetector/","link":"","permalink":"http://example.com/2022/01/07/OpenCV/FaceDetector/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"OpenGLES_FBO","slug":"Android/OpelGLES/OpenGLES_FBO","date":"2022-01-07T01:48:00.000Z","updated":"2022-01-08T05:06:37.727Z","comments":true,"path":"2022/01/07/Android/OpelGLES/OpenGLES_FBO/","link":"","permalink":"http://example.com/2022/01/07/Android/OpelGLES/OpenGLES_FBO/","excerpt":"","text":"基本知识 1. Android系统默认渲染器 OpenGL,系统启动时，经过BootLoader启动，kernel启动----&gt;init进程启动核心进程（ServiceManager,zygote,OpenGL)----&gt;播放开机动画 OpenGL渲染管线的最后一个阶段就是帧缓冲区（FrameBuffer) 2. OpenGL渲染管线的最后阶段FrameBuffer,Android系统存在默认缓冲区（window-system-provided frame),用于屏幕显示。GPU往显示缓冲区写入数据时，屏幕会显示缓冲内容。 使用FBO可以让数据不渲染到屏幕上，渲染到离屏的Buffer中 Android中后台给视频添加水印，Camera实时滤镜，需要把原数据经过处理后保存但是不显示数据 3.对于默认的相机，使用系统提供的OpenGL渲染的帧缓冲区（OES），OpenGL所有渲染结果直接到达帧缓冲区----&gt;on-Srceen渲染方式 对于贴纸相机，使用帧缓冲区对象，OpenGL将提供给窗口的帧缓冲区重定向FBO之中 4. FBO提供缓冲区：颜色缓冲区，深度缓冲区，模板缓冲区 FBO提供2种绑定的对象：纹理图片(texture images) 和 渲染图像(renderbuffer images) 4.1 纹理绑定FBO,OpenGL执行渲染到纹理操作 4.2 渲染绑定FBO，OpenGL执行离屏渲染 4.3 通过GL_MAX_COLOR_ATTACHMENTS查询颜色缓冲区挂节点 4.4 纹理对象 glFramebufferTexture2D 渲染对象 glFramebufferRenderbuffer 5. FBO (Frame Buffer Object) 帧缓冲区对象，FBO本身不能用于渲染，只有添加了纹理或者渲染缓冲区后才能作为渲染目标 6. FBO 使用流程图 使用1.搭建基本OpenGLES FBO 仅输出 纹理对象1.1 12protected int[] mFrameBuffers;protected int[] mFrameBufferTextures; 1.2123456789101112131415161718192021GlUtil.checkGlError(TAG, &quot;[onReady()][Start]&quot;);super.onReady(width, height);if (mFrameBuffers != null) &#123; destroyFrameBuffers();&#125;mFrameBuffers = new int[1];//1 创建fboGLES20.glGenFramebuffers(mFrameBuffers.length, mFrameBuffers, 0);mFrameBufferTextures = new int[1];//2 创建fbo纹理GlUtil.glConfigureTextures(mFrameBufferTextures);//3 绑定纹理GLES20.glBindTexture(GLES20.GL_TEXTURE_2D, mFrameBufferTextures[0]);GLES20.glTexImage2D(GLES20.GL_TEXTURE_2D, 0, GLES20.GL_RGBA, mOutputWidth, mOutputHeight, 0, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, null);//4 fbo绑定纹理GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, mFrameBuffers[0]);GLES20.glFramebufferTexture2D(GLES20.GL_FRAMEBUFFER, GLES20.GL_COLOR_ATTACHMENT0, GLES20.GL_TEXTURE_2D, mFrameBufferTextures[0], 0);//5 解绑GLES20.glBindTexture(GLES20.GL_TEXTURE_2D, 0);GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, 0);GlUtil.checkGlError(TAG, &quot;[onReady()][End]&quot;); 2.使用FBO处理图片滤镜(自己创建FrameBuffer,同时输出到纹理对象，渲染对象)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public void createEnvi() &#123; Log.d(TAG, &quot;[createEnvi]&quot;); //创建帧缓冲对象 GLES20.glGenFramebuffers(1, fFrame, 0); //创建渲染缓冲对象 GLES20.glGenRenderbuffers(1, fRender, 0); //相似地，我们打算把渲染缓冲对象绑定，这样所有后续渲染缓冲操作都会影响到当前的渲染缓冲对象 GLES20.glBindRenderbuffer(GLES20.GL_RENDERBUFFER, fRender[0]); //创建一个深度和模板渲染缓冲对象 GLES20.glRenderbufferStorage(GLES20.GL_RENDERBUFFER, GLES20.GL_DEPTH_COMPONENT16, mBitmap.getWidth(), mBitmap.getHeight()); //附加帧缓冲 渲染缓冲对象附加到帧缓冲的深度和模板附件 GLES20.glFramebufferRenderbuffer(GLES20.GL_FRAMEBUFFER, GLES20.GL_DEPTH_ATTACHMENT, GLES20.GL_RENDERBUFFER, fRender[0]); //解绑渲染缓冲 GLES20.glBindRenderbuffer(GLES20.GL_RENDERBUFFER, 0); //fTexture size 2 //fTexture[0] 普通纹理（由bitmap转成) //fTexture[1] 帧缓冲纹理(GLES20.glTextImage2D) GLES20.glGenTextures(2, fTexture, 0); for (int i = 0; i &lt; 2; i++) &#123; GLES20.glBindTexture(GLES20.GL_TEXTURE_2D, fTexture[i]); if (i == 0) &#123; GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, GLES20.GL_RGBA, mBitmap, 0); &#125; else &#123;//纹理的维度设置为图片的大小,传递null作为纹理的data,只分配内存，不写入数据 GLES20.glTexImage2D(GLES20.GL_TEXTURE_2D, 0, GLES20.GL_RGBA, mBitmap.getWidth(), mBitmap.getHeight(), 0, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, null); &#125; GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MIN_FILTER, GLES20.GL_NEAREST); GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MAG_FILTER, GLES20.GL_LINEAR); GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_S, GLES20.GL_CLAMP_TO_EDGE); GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_T, GLES20.GL_CLAMP_TO_EDGE); &#125; mBuffer = ByteBuffer.allocate(mBitmap.getWidth() * mBitmap.getHeight() * 4);&#125; //绑定执行GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, fFrame[0]);//将创建好的帧缓冲纹理附加到帧缓冲 纹理对象GLES20.glFramebufferTexture2D(GLES20.GL_FRAMEBUFFER, GLES20.GL_COLOR_ATTACHMENT0, GLES20.GL_TEXTURE_2D, fTexture[1], 0);//FBO挂接 渲染对象 Renderbuffer 渲染缓冲 对象的一大优点是，它以OpenGL原生渲染格式储存它的数据，因此在离屏渲染到帧缓冲的时候，这些数据就相当于被优化过的了GLES20.glFramebufferRenderbuffer(GLES20.GL_FRAMEBUFFER, GLES20.GL_DEPTH_ATTACHMENT, GLES20.GL_RENDERBUFFER, fRender[0]);GLES20.glViewport(0, 0, mBitmap.getWidth(), mBitmap.getHeight());mFilter.setTextureId(fTexture[0]);mFilter.draw(); GLES20.glReadPixels(0, 0, mBitmap.getWidth(), mBitmap.getHeight(), GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, mBuffer);if (mCallback != null) &#123; mCallback.onCall(mBuffer);&#125;deleteEnvi();mBitmap.recycle(); 3. 使用FBO处理相机纹理3.1获取相机纹理后，最后返回步骤1中生成的mFrameBufferTextures[0]，即可对相机纹理进行多个滤镜或者变换处理123456789101112131415161718192021GlUtil.checkGlError(TAG, &quot;[onDrawFrame()][Start]&quot;);GLES20.glViewport(left_margin, 0, mOutputWidth, mOutputHeight);GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, mFrameBuffers[0]);GLES20.glUseProgram(mGLProgramId);mGLVertexBuffer.position(0);GLES20.glVertexAttribPointer(vPosition, 2, GLES20.GL_FLOAT, false, 0, mGLVertexBuffer);GLES20.glEnableVertexAttribArray(vPosition);mGLTextureBuffer.position(0);GLES20.glVertexAttribPointer(vCoord, 2, GLES20.GL_FLOAT, false, 0, mGLTextureBuffer);GLES20.glEnableVertexAttribArray(vCoord);GLES20.glUniformMatrix4fv(vMatrix, 1, false, matrix, 0);GLES20.glActiveTexture(GLES20.GL_TEXTURE0);GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, textureId);GLES20.glUniform1i(vTexture, 0);GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP, 0, 4);GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, 0);GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, 0);GlUtil.checkGlError(TAG, &quot;[onDrawFrame()][Start]&quot;);return mFrameBufferTextures[0];//返回创建好的纹理对象-----&gt;进行后续的操作 4.释放12345678910111213141516171819 private void deleteEnvi() &#123; GLES20.glDeleteTextures(2, fTexture, 0); GLES20.glDeleteRenderbuffers(1, fRender, 0); GLES20.glDeleteFramebuffers(1, fFrame, 0); &#125;private void destroyFrameBuffers() &#123; if (mFrameBufferTextures != null) &#123; GLES20.glDeleteTextures(1, mFrameBufferTextures, 0); mFrameBufferTextures = null; &#125; if (mFrameBuffers != null) &#123; GLES20.glDeleteFramebuffers(1, mFrameBuffers, 0); mFrameBuffers = null; &#125; &#125; 5.参考 MrYeLiang Android-OpenGL-Filter 相机纹理3次FBO纹理变化 湖广午王 AndroidOpenGLDemo FBO 图片灰度滤镜 6.Camera2+GLSurfaceView+FBO","categories":[{"name":"OpenGLES","slug":"OpenGLES","permalink":"http://example.com/categories/OpenGLES/"}],"tags":[{"name":"OpenGLES","slug":"OpenGLES","permalink":"http://example.com/tags/OpenGLES/"}]},{"title":"Camera_GlSurfaceView","slug":"Android/Camera2/Camera2_GlSurfaceView","date":"2022-01-07T01:46:14.000Z","updated":"2022-01-08T03:21:10.841Z","comments":true,"path":"2022/01/07/Android/Camera2/Camera2_GlSurfaceView/","link":"","permalink":"http://example.com/2022/01/07/Android/Camera2/Camera2_GlSurfaceView/","excerpt":"","text":"基本概念:屏幕方向 ScreenOrientation:0度使用Android的GLSurfaceView显示时，得出结论：摄像头后置：摄像头ID “0”Surface.ROTATION_0 画面需要逆时针旋转90度，同时调整GLSurfaceView的显示比例Surface.ROTATION_90 画面方向无需处理Surface.ROTATION_180 画面方向无需处理Surface.ROTATION_270 湖面需要顺时针旋转180度，同时调整GLSurfaceView的显示比例 Camera2打开相机1.仅用来显示：获取当前显示屏幕的DisplayWidth,DisplayHeight(屏幕的宽高) 2.仅用来显示：获取需要打开摄像头的Preview的Size属性(cameraCharacteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)),获取其中最符合屏幕比例且分辨率大的PreViewSize 3.通过CameraManager.OpenCamera()方法打开相机设置 4.通过CaptureRequest.Builde设置相机的Target(可以设置多个) 例如：通过GLES生成OES纹理并绑定到SurfaceTexture上，通过并将SurfaceTexture设置宽高(1,2步骤获取)后，添加到Surface上，最后将Surface添加到 CaptureRequest.Builde.addTarget(surface); 例如：创建ImageReader，并将其Surface(getSurface()),添加到CaptureRequest.Builde.addTarget(surface); 结论：CaptureRequest.Builde.addTarget(Surface)方法的意义在于将目标Surface(提前设置宽高)传递给相机，相机生产方可以同时将不同分辨率的数据传递给不同消费者。 消费者：TextureView,GLSurfaceView,ImageReader等 显示相机画面1.通过GLSurfaceView显示相机画面(绑定OES纹理，自定义GLSurfaceView.Renderer)即可，画面方向以及比例可以通过顶点坐标或者相机Matrix来进行调节 2.通过TextureView显示相机画面，将TextureView.getSurfaceTexture()方法，设置target同理，可以对TextureView进行旋转，平移操作，保证画面比例正常 ImageReader创建1.ImageReader的可以用来获取相机的帧数据，通过对帧数据的处理，实现对象检测,人脸检测,等需要单帧处理的场景 2.在很多官方例子中便可以看到，例如： 2.1 TFLite ObjectDetect 中将Image数据转成Bitmap然后传递给识别接口 2.2 OpenCV Face Detect中将Image数据转成Mat,然后将灰度Mat传递给识别接口 2.3 人脸识别以及landmark中通过将Image数据转换成为NV21类型，传递给识别接口 3. 显示相机画面时部分Orientation进行旋转操作，同理ImageReader获取到的接口也需要进行处理，方可得到正确方向的数据。 ImageReader转码 OpenCV转码(来源于OpenCV SDK官方实现 ImageFormat.YUV_420_888转Mat) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class Yuv4208882Mat implements CvCameraViewFrame &#123; public Mat gray() &#123; Image.Plane[] planes = mImage.getPlanes(); int w = mImage.getWidth(); int h = mImage.getHeight(); assert (planes[0].getPixelStride() == 1); ByteBuffer y_plane = planes[0].getBuffer(); int y_plane_step = planes[0].getRowStride(); mGray = new Mat(h, w, CvType.CV_8UC1, y_plane, y_plane_step); return mGray; &#125; public Mat rgba() &#123; Image.Plane[] planes = mImage.getPlanes(); int w = mImage.getWidth(); int h = mImage.getHeight(); int chromaPixelStride = planes[1].getPixelStride(); if (chromaPixelStride == 2) &#123; // Chroma channels are interleaved assert (planes[0].getPixelStride() == 1); assert (planes[2].getPixelStride() == 2); ByteBuffer y_plane = planes[0].getBuffer(); int y_plane_step = planes[0].getRowStride(); ByteBuffer uv_plane1 = planes[1].getBuffer(); int uv_plane1_step = planes[1].getRowStride(); ByteBuffer uv_plane2 = planes[2].getBuffer(); int uv_plane2_step = planes[2].getRowStride(); Mat y_mat = new Mat(h, w, CvType.CV_8UC1, y_plane, y_plane_step); Mat uv_mat1 = new Mat(h / 2, w / 2, CvType.CV_8UC2, uv_plane1, uv_plane1_step); Mat uv_mat2 = new Mat(h / 2, w / 2, CvType.CV_8UC2, uv_plane2, uv_plane2_step); long addr_diff = uv_mat2.dataAddr() - uv_mat1.dataAddr(); if (addr_diff &gt; 0) &#123; assert (addr_diff == 1); Imgproc.cvtColorTwoPlane(y_mat, uv_mat1, mRgba, Imgproc.COLOR_YUV2RGBA_NV12); &#125; else &#123; assert (addr_diff == -1); Imgproc.cvtColorTwoPlane(y_mat, uv_mat2, mRgba, Imgproc.COLOR_YUV2RGBA_NV21); &#125; return mRgba; &#125; else &#123; // Chroma channels are not interleaved byte[] yuv_bytes = new byte[w * (h + h / 2)]; ByteBuffer y_plane = planes[0].getBuffer(); ByteBuffer u_plane = planes[1].getBuffer(); ByteBuffer v_plane = planes[2].getBuffer(); int yuv_bytes_offset = 0; int y_plane_step = planes[0].getRowStride(); if (y_plane_step == w) &#123; y_plane.get(yuv_bytes, 0, w * h); yuv_bytes_offset = w * h; &#125; else &#123; int padding = y_plane_step - w; for (int i = 0; i &lt; h; i++) &#123; y_plane.get(yuv_bytes, yuv_bytes_offset, w); yuv_bytes_offset += w; if (i &lt; h - 1) &#123; y_plane.position(y_plane.position() + padding); &#125; &#125; assert (yuv_bytes_offset == w * h); &#125; int chromaRowStride = planes[1].getRowStride(); int chromaRowPadding = chromaRowStride - w / 2; if (chromaRowPadding == 0) &#123; // When the row stride of the chroma channels equals their width, we can copy // the entire channels in one go u_plane.get(yuv_bytes, yuv_bytes_offset, w * h / 4); yuv_bytes_offset += w * h / 4; v_plane.get(yuv_bytes, yuv_bytes_offset, w * h / 4); &#125; else &#123; // When not equal, we need to copy the channels row by row for (int i = 0; i &lt; h / 2; i++) &#123; u_plane.get(yuv_bytes, yuv_bytes_offset, w / 2); yuv_bytes_offset += w / 2; if (i &lt; h / 2 - 1) &#123; u_plane.position(u_plane.position() + chromaRowPadding); &#125; &#125; for (int i = 0; i &lt; h / 2; i++) &#123; v_plane.get(yuv_bytes, yuv_bytes_offset, w / 2); yuv_bytes_offset += w / 2; if (i &lt; h / 2 - 1) &#123; v_plane.position(v_plane.position() + chromaRowPadding); &#125; &#125; &#125; Mat yuv_mat = new Mat(h + h / 2, w, CvType.CV_8UC1); yuv_mat.put(0, 0, yuv_bytes); Imgproc.cvtColor(yuv_mat, mRgba, Imgproc.COLOR_YUV2RGBA_I420, 4); return mRgba; &#125; &#125; public Yuv4208882Mat(Image image) &#123; super(); mImage = image; mRgba = new Mat(); mGray = new Mat(); &#125; public void release() &#123; mRgba.release(); mGray.release(); &#125; private Image mImage; private Mat mRgba; private Mat mGray;&#125; 例子TFLite Object Detector(ImageFormat.YUV_420_888转Bitmap) 1234567891011121314151617181920212223242526272829303132333435363738private void saveBitmapFromBytes(Image image) &#123; Image.Plane[] planes = image.getPlanes(); byte[][] yuvBytes = new byte[3][]; fillBytes(planes, yuvBytes); int yRowStride = planes[0].getRowStride(); int uvRowStride = planes[1].getRowStride(); int uvPixelStride = planes[1].getPixelStride(); ImageUtils.convertYUV420ToARGB8888( yuvBytes[0], yuvBytes[1], yuvBytes[2], mPreviewSize.getWidth(), mPreviewSize.getHeight(), yRowStride, uvRowStride, uvPixelStride, rgbBytes); Bitmap rgbFrameBitmap = Bitmap.createBitmap(mPreviewSize.getWidth(), mPreviewSize.getHeight(), Bitmap.Config.ARGB_8888); rgbFrameBitmap.setPixels(rgbBytes, 0, mPreviewSize.getWidth(), 0, 0, mPreviewSize.getWidth(), mPreviewSize.getHeight()); File file = new File(activity.getExternalCacheDir() + &quot;/&quot; + System.currentTimeMillis() + &quot;_compress.jpeg&quot;); if (!file.exists()) &#123; file.getParentFile().mkdirs(); try &#123; file.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); Logger.e(TAG, &quot;[imageAvailableListenerDetect]&quot;); return; &#125; &#125; try &#123; rgbFrameBitmap.compress(Bitmap.CompressFormat.JPEG, 10, new FileOutputStream(file)); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; &#125; 例子3 部分人脸识别(ImageFormat.YUV_420_888转NV21) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public static byte[] getDataFromImage(Image image, int colorFormat) &#123; if (colorFormat != COLOR_FormatI420 &amp;&amp; colorFormat != COLOR_FormatNV21) &#123; throw new IllegalArgumentException(&quot;only support COLOR_FormatI420 &quot; + &quot;and COLOR_FormatNV21&quot;); &#125; if (!isImageFormatSupported(image)) &#123; throw new RuntimeException(&quot;can&#x27;t convert Image to byte array, format &quot; + image.getFormat()); &#125; Rect crop = image.getCropRect(); int format = image.getFormat(); int width = crop.width(); int height = crop.height(); Image.Plane[] planes = image.getPlanes(); byte[] data = new byte[width * height * ImageFormat.getBitsPerPixel(format) / 8]; byte[] rowData = new byte[planes[0].getRowStride()]; int channelOffset = 0; int outputStride = 1; for (int i = 0; i &lt; planes.length; i++) &#123; switch (i) &#123; case 0: channelOffset = 0; outputStride = 1; break; case 1: if (colorFormat == COLOR_FormatI420) &#123; channelOffset = width * height; outputStride = 1; &#125; else if (colorFormat == COLOR_FormatNV21) &#123; channelOffset = width * height + 1; outputStride = 2; &#125; break; case 2: if (colorFormat == COLOR_FormatI420) &#123; channelOffset = (int) (width * height * 1.25); outputStride = 1; &#125; else if (colorFormat == COLOR_FormatNV21) &#123; channelOffset = width * height; outputStride = 2; &#125; break; &#125; ByteBuffer buffer = planes[i].getBuffer(); int rowStride = planes[i].getRowStride(); int pixelStride = planes[i].getPixelStride(); int shift = (i == 0) ? 0 : 1; int w = width &gt;&gt; shift; int h = height &gt;&gt; shift; buffer.position(rowStride * (crop.top &gt;&gt; shift) + pixelStride * (crop.left &gt;&gt; shift)); for (int row = 0; row &lt; h; row++) &#123; int length; if (pixelStride == 1 &amp;&amp; outputStride == 1) &#123; length = w; buffer.get(data, channelOffset, length); channelOffset += length; &#125; else &#123; length = (w - 1) * pixelStride + 1; buffer.get(rowData, 0, length); for (int col = 0; col &lt; w; col++) &#123; data[channelOffset] = rowData[col * pixelStride]; channelOffset += outputStride; &#125; &#125; if (row &lt; h - 1) &#123; buffer.position(buffer.position() + rowStride - length); &#125; &#125; &#125; return data;&#125; 总结：Image的转码核心在于提取Y,U,V3个通道的数据后按照规定数据进行转换或者重新排列即可 参照例子 OpenCV Android SDK 4.5.2 (自行下载使用) TFLite Object Detect","categories":[{"name":"Android","slug":"Android","permalink":"http://example.com/categories/Android/"}],"tags":[{"name":"相机","slug":"相机","permalink":"http://example.com/tags/%E7%9B%B8%E6%9C%BA/"}]},{"title":"java_String","slug":"java/lang/String","date":"2020-12-15T15:11:08.000Z","updated":"2022-01-04T13:26:28.906Z","comments":true,"path":"2020/12/15/java/lang/String/","link":"","permalink":"http://example.com/2020/12/15/java/lang/String/","excerpt":"","text":"Char1. String 底层实现为 char[]-----&gt;private final char value[]//char[] 数组 2. String类为final类，也就是无法通过子类去继承。（final修饰的方法无法复写) String### 1. String 实现了接口列表 #### 1.1 java.io.Serialliable 序列化 #### 1.2 Comparable&lt;String&gt;----&gt;public int compareTo(String) 此接口用来设置排序的规则 #### 1.3 CharSequence ### 2. String 内部实现 #### 2.1 private final char value[];//使用字符数组进行存储 #### 2.2 private int hash;//缓存字符串的哈希值 ### 3. String 方法 #### 3.1 String的构造方法中，涉及charset，使用到了StringCode类以及使用Arrays.copyof() 通过对char数组进行拷贝 StringBuilder### 1. StringBuilder A mutable sequence of characters.（可变序列序列），but with no guarantee of synchronization(但是无法保证同步)，used by a single thread,it will be faster under most implementation. ### 2. StringBuilder 同样为final类，无法通过子类继承去修改实现,继承AbstractStringBuilder, 实现的接口列表 2.1 java.io.Serializable 序列化 2.2 CharSequence StringBuffer### 2. StringBuffer 延申知识### 1. java.lang.Comparable的使用 o:specified object return: a negative integer less than zero equal to a positive integer greater than public int compareTo(T o); 查看String的源码发现实现此接口，String的比大小规则:两个字符串均从第一个字符起，比较字符的Unicode Value的大小 123456789101112131415161718public int compareTo(String anotherString) &#123; int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; return len1 - len2;&#125; ### 2. 其他地方的使用 Lists (and arrays) of objects that implement this interface can be sorted automatically by Collection#sort(list) Collections.sort And Arrays.srot(Object[]) Arrays.sort. 这里提供集合对象的排序可以自动使用2个实现。 Collections.class 1234public static &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List&lt;T&gt; list) &#123; list.sort(null);&#125; List.class 1234567891011@SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;rawtypes&quot;&#125;)default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; Arrays.class ``` public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125; &#125; ``` ### 3.CharSequence 3.1简介 &lt;tt&gt;CharSequence&lt;/tt&gt; is a readable sequence of &lt;code&gt;char&lt;/code&gt; values. This interface provides uniform, read-only access to many different kinds of &lt;code&gt;char&lt;/code&gt; sequences. 此接口提供对于char的可读序列，可以用来提供统一，仅读 对于各种各样的char序列(String,StringBuilder,StringBuffer)","categories":[{"name":"Java源码","slug":"Java源码","permalink":"http://example.com/categories/Java%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java源码","slug":"Java源码","permalink":"http://example.com/tags/Java%E6%BA%90%E7%A0%81/"}]},{"title":"Java集合","slug":"java/util/java集合相关","date":"2020-12-13T12:41:02.000Z","updated":"2021-01-05T14:14:04.857Z","comments":true,"path":"2020/12/13/java/util/java集合相关/","link":"","permalink":"http://example.com/2020/12/13/java/util/java%E9%9B%86%E5%90%88%E7%9B%B8%E5%85%B3/","excerpt":"","text":"源码类图 源码学习1.List1.1 Vector 在线查看 Vector实现是数组，默认空构造方法长度为10，也可以根据传入initialCapacity 12345678910111213public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125;public Vector(int initialCapacity) &#123; this(initialCapacity, 0);&#125;public Vector() &#123; this(10);&#125; Vector使用时 允许添加value是null size(),isEmpty(),get(index),set(int,E),add() 方法的执行时间复杂度O(1),注意这里的关键字Synchronized 1234567891011121314151617181920212223242526272829public synchronized int size() &#123; return elementCount;&#125;public synchronized boolean isEmpty() &#123; return elementCount == 0;&#125; public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125;public synchronized E set(int index, E element) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125; 线程是否安全？ 肯定的哈，这么多synchronized 扩容:看到这里发现了个”+”,原来是2倍 1234567891011grow(minCapacity);private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 扩容本质: 1Arrays.copyOf(elementData, newCapacity) Vector看起来平常很少用哈！！！ 1.2 ArrayList 在线查看 ArrayList实现是一个数组，默认长度10，size（int）表示长度。代码摘选如下： 123private static final int DEFAULT_CAPACTITY=10;//默认长度transient Object[] elementData;//基本实现数组private int size;//大小 ArrayList 使用时 允许添加value是null的值 size(),isEmpty(),get(index),set(),add()方法的执行时间复杂度均为O(1),这里的时间复杂度表示访问单个元素时，因为访问只需要一条指令。 12345678910111213141516171819202122232425262728293031//返回List的大小实现public int size() &#123;return size;&#125;//返回List是否为空public boolean isEmpty() &#123; return size == 0;&#125;//根据index返回valuepublic E get(int index) &#123; rangeCheck(index); // 检查是否越界 return elementData(index);// 返回ArrayList的elementData数组index位置的元素&#125;//设置index的valuepublic E set(int index, E element) &#123; rangeCheck(index); // 检查是否越界 E oldValue = elementData(index);// 调用elementData(index)获取到当前位置的 elementData[index] = element; // 将element赋值到ArrayList的elementData数组的第index位置 return oldValue;&#125;//添加一个值(在添加时未进行null判断，所有ArrayLsit是允许空值存在)public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // 扩容 // Increments modCount!! elementData[size++] = e; // 将e赋值给elementData的size+1的位置 return true;&#125; 线程是否安全？ 不安全，这里并未看到对方法或者全局变量使用synchronized关键字。以及size并未使用volatile修饰 扩容规则 扩容大小为原大小的1.5倍,后使用Arrays.copyof(old,new) 123456789private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; // 获取到ArrayList中elementData数组的内存空间长度 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);// 扩容至原来的1.5倍 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0)//若预设值大于默认的最大值检查是否溢出 newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);// 并将elementData的数据复制到新的内存空间&#125; 扩容的本质： 1System.arraycopy(elementData, 0, newElementData, 0,Math.min(elementData.length,newCapacity)) 使用总结 ArrayList删除时间复杂度为O(1),且允许删除null值 ArrayList全局变量且多线程使用时，存在问题.作为局部变量，放心用吧！！！ 可以使用的Collections#synchronizedList保证线程安全 使用ArrayList时为了便面多次copy的过程,可以在初始化时指定固定大小 1.2 LinkedList 在线查看 LinkedList底层数据结构是一个双向链表，既然是双向链表。可以被当作栈，队列。非线程安全 123transient int size=0;transient Node&lt;E&gt; first;//transient 防止序列化transient Node&lt;E&gt; last; LinkedList 方法实现(这里只对思路和public方法记录下) 头节点插入 1234567891011private void linkFirst(E e)&#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null,e,f); first = newNode; if(f == null) last = newNode; else f.prev = newNode; size++; modCount++; &#125; 尾节点插入(不做笔记) 在succ节点前插入 1234567891011void linkBefore(E e,Node&lt;E&gt; succ)&#123; final Node&lt;E&gt; pred = succ.prev;//保存前一个节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred,e,succ);//创建一个新的节点 succ.prev = newNode;//succ的前节点设置为newNode if(pred==null) first = newNode; else pred.next = newNode; size++; modCount++; &#125; 删除非空节点 获取首节点,并且返回头节点值 123456public E getFirst()&#123; final Node&lt;E&gt; f = first; if(f==null) throw new NoSuchElementException(); return f.item &#125; 获取尾节点，返回存储的元素值 在头节点插入 判断元素是否包含 12345 public boolean contains(Object o)&#123; return indexOf(o)!=-1; &#125; ``` - 查询操作返回对应的Index public int indexOf(Object o)&#123; int index = 0; if(o==null)&#123; for(Node&lt;E&gt; x= first;x!=null;x=x.next)&#123; if(x.itme==null) return index; index++; &#125; &#125;else&#123; for(Node&lt;E&gt; x= first;x!=null;x=x.next)&#123; if(o.equals(x.item)) return index; index++; &#125; &#125; &#125; 123456789 - 获取头节点 peeK() - 获取并删除头节点 poll() - 等等（这些方法的实现还是比较简单，都是比较常规的操作)### 2.Map#### 2.1 HashMap- [在线查看](https://github.com/wupeixuan/JDKSourceCode1.8/blob/master/src/java/util/HashMap.java)- HashMap底层数据结构 数组+链表+红黑树，当链表的长度大于等于8时，链表会转换成为红黑树，当红黑树的大小小于等于6时，红黑树会转换成为链表。 static final int DEFAULT_ININIAL_CAPCITY=1&lt;&lt;4;//默认16 static final int MAXIMUM_CAPACITY =1&lt;&lt;30;//最大 transient Node&lt;K,V&gt;[] table;//存储数组的元素 static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt;{}//红黑树的实现 static class Node&lt;K, V&gt; implements Map.Entry&lt;K, V&gt;{}//链表的节点``` 2.1.1 LinkedHashMap2.2 TreeMap2.3 HashTable2.4 EnumMap3.Set3.1 HashSet3.1.1 LinkedHashSet3.2 TreeSetSortedSet","categories":[{"name":"Java源码","slug":"Java源码","permalink":"http://example.com/categories/Java%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java源码","slug":"Java源码","permalink":"http://example.com/tags/Java%E6%BA%90%E7%A0%81/"}]},{"title":"Hexo+Github+fluid搭建","slug":"my-site","date":"2020-12-12T11:10:53.000Z","updated":"2021-09-14T14:17:57.478Z","comments":true,"path":"2020/12/12/my-site/","link":"","permalink":"http://example.com/2020/12/12/my-site/","excerpt":"","text":"Hexo+Github+fluid搭建记录主体流程1.Github 注册账号,创建”*.github.io”的仓库2.安装Node.js后,使用npm install hexo3.修改默认theme为fluid 需要参考的链接GithubNode.jsHexoFluid 创建博客的原因 一名Android开发 日常记录以上这些模块曾经已经整理详细学习记录（软件&amp;硬件知识)，希望在后续维护中，补充上来！！！ 其他知识模块如下 2.1 Android Camera(相机应用) 2.2 Android OpenGLES(图像处理) 2.3 Android AI(TFLite) 学习方向 3.1 美颜算法了解和学习 3.2 算法题","categories":[{"name":"其他","slug":"其他","permalink":"http://example.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"工具使用记录","slug":"工具使用记录","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-12-12T11:04:53.223Z","updated":"2020-12-12T11:04:53.223Z","comments":true,"path":"2020/12/12/hello-world/","link":"","permalink":"http://example.com/2020/12/12/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"OpenGLES","slug":"OpenGLES","permalink":"http://example.com/categories/OpenGLES/"},{"name":"Android","slug":"Android","permalink":"http://example.com/categories/Android/"},{"name":"Java源码","slug":"Java源码","permalink":"http://example.com/categories/Java%E6%BA%90%E7%A0%81/"},{"name":"其他","slug":"其他","permalink":"http://example.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"OpenGLES","slug":"OpenGLES","permalink":"http://example.com/tags/OpenGLES/"},{"name":"相机","slug":"相机","permalink":"http://example.com/tags/%E7%9B%B8%E6%9C%BA/"},{"name":"Java源码","slug":"Java源码","permalink":"http://example.com/tags/Java%E6%BA%90%E7%A0%81/"},{"name":"工具使用记录","slug":"工具使用记录","permalink":"http://example.com/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/"}]}